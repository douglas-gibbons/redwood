model:
  # name: gemini-2.5-pro
  name: gemini-2.5-flash
  api_key: API-KEY-HERE

# Safety valve, in case of looping
max_model_calls: 20

logging:
  level: INFO
  file: /tmp/redwood.log

token_storage:
  enabled: false
  location: ~/config/redwood_auth_tokens/ # Directory
  # Make a new token storage key with
  # dd if=/dev/urandom bs=32 count=1 2>/dev/null | openssl base64`
  encryption_key: E/YIKS+62be/MlYpGHlrXW4lW/fgB/DzFx3SrPgsKJ0=

mcp:

  # Redwood Internal Tools
  - name: redwood
    ask: true # ask the user before running tools
    command: uv
    args:
      - "run"
      - "server"

  ## Sequential Thinking
  #
  # - name: sequentialthinking
  #   ask: false # ask the user before running tools
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-sequential-thinking"

  ## DuckDuckGo web search
  #
  # - name: duckduckgo
  #   ask: false
  #   command: uvx
  #   args:
  #     - "duckduckgo-mcp-server"

  ## Filesystem
  #
  # - name: filesystem
  #   ask: true
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-filesystem"
  #     - "/home"

  ## Atlassian
  ##
  ## uses the SSE protocol, and connects with OAUTH2, so this will
  ## open a browser window for authentication
  #
  # - name: atlassian
  #   ask: false
  #   url: https://mcp.atlassian.com/server/v1/sse
  #   protocol: sse

  # HTTP Example Tool with headers
  # - name: http-example
  #   url: https://api.example.com/v1/stream
  #   headers:
  #     Authorization: Bearer API-KEY-HERE


prompt: |
  You are an AI personal assistant who helps a user with day-to-day tasks

  # Remember
  
  * Keep responses brief, but professional and useful
  * Use the tools available to you via MCP to answer questions and perform tasks
  * If you are unsure about something, use the tools to find out more information
  * Always think step-by-step about how to use the tools to achieve the user's goals
  * The agent configuration file is located at ~/ .config/redwood.yaml
